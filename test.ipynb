{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "4\n",
      "[2. 3. 0. 1. 3. 2. 2. 2. 2. 0. 3. 1. 2. 3. 0. 2. 3. 1. 3. 3. 2. 0. 0. 3.\n",
      " 0. 2. 3. 1. 2. 0. 3. 0. 1. 3. 1. 3. 3. 0. 0. 0. 0. 2. 3. 0. 0. 3. 3. 1.\n",
      " 2. 1. 2. 1. 3. 1. 1. 3. 2. 0. 0. 0. 0. 3. 0. 3. 1. 1. 1. 2. 3. 3. 1. 2.\n",
      " 1. 2. 3. 3. 0. 3. 1. 0. 0. 2. 1. 3. 0. 2. 0. 1. 1. 3. 3. 0. 1. 2. 1. 1.\n",
      " 1. 1. 1. 1. 3. 2. 2. 3. 0. 0. 0. 2. 0. 0. 0. 3. 3. 3. 3. 1. 2. 2. 0. 1.\n",
      " 2. 3. 2. 0. 2. 2. 0. 0. 0. 2. 3. 2. 2. 1. 3. 3. 0. 0. 1. 3. 3. 2. 1. 1.\n",
      " 2. 1. 2. 3. 3. 1. 1. 3. 2. 3. 0. 3. 2. 1. 2. 2. 0. 1. 1. 1. 2. 1. 1. 3.\n",
      " 2. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1. 1. 0. 1. 3. 0. 2. 2. 2. 3. 2. 1. 0. 2.\n",
      " 1. 0. 1. 1.]\n",
      "[array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1]), array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]), array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "class ComplementaryMaskingGenerator:\n",
    "    def __init__(\n",
    "            self, input_size, ratio_masking_patches):\n",
    "\n",
    "        if not isinstance(input_size, tuple):\n",
    "            input_size = (input_size, ) * 2\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        \n",
    "        self.num_patches = self.height * self.width\n",
    "        self.num_masking_patches = ratio_masking_patches * self.num_patches\n",
    "        assert (self.num_masking_patches).is_integer() and (self.num_patches%self.num_masking_patches==0),'Number of patches should be integer and identical'\n",
    "        self.num_set = int(1/ratio_masking_patches)\n",
    "    def __repr__(self):\n",
    "        repr_str = \"Maks: total patches {}, mask patches {}\".format(\n",
    "            self.num_patches, self.num_masking_patches\n",
    "        )\n",
    "        return repr_str\n",
    "    def __call__(self):\n",
    "        print(int(self.num_patches - self.num_masking_patches))\n",
    "        print(self.num_set)\n",
    "        stack_lst = [np.ones(int(self.num_masking_patches)) * i for i in range(self.num_set)]\n",
    "        mask = np.hstack(stack_lst)\n",
    "        np.random.shuffle(mask)\n",
    "        rst = []\n",
    "        for i in range(self.num_set):\n",
    "            rst.append((mask==i)*1)\n",
    "        return mask,rst\n",
    "cmg = ComplementaryMaskingGenerator(14,0.25)\n",
    "m,a = cmg()\n",
    "print(m)\n",
    "print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import furnace.utils as utils\n",
    "import torch.nn.functional as F\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from math import factorial\n",
    "def get_combination_of(n:int=4,m=2)->list:\n",
    "    '''\n",
    "    This func returns the combination of the designated integer n.\n",
    "\n",
    "    '''\n",
    "    iter_lst = [i for i in range(n)]\n",
    "    return list(itertools.combinations(iter_lst, m))\n",
    "\n",
    "\n",
    " \n",
    "def get_comb(n=4,m=2):\n",
    "    '''\n",
    "    works for Python < 3.8.\n",
    "    If your installed version of Python > 3.8, use math.comb(n,2) instead.\n",
    "    '''\n",
    "    if m <= n:\n",
    "        rst=factorial(n)/(factorial(n-m) * factorial(m))\n",
    "    return int(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comb(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 27176.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for combination_set in tqdm(get_combination_of(4)):\n",
    "    print(combination_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2, 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_combination_of(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  5,   7,  10,  12,  13,  19,  20,  23,  27,  44,  45,  51,  59,\n",
      "        63,  65,  66,  68,  72,  78,  79,  82,  84,  86,  92,  98,  99,\n",
      "       105, 109, 113, 122, 123, 124, 131, 132, 134, 135, 141, 142, 150,\n",
      "       151, 161, 164, 167, 172, 180, 182, 188, 189, 193]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(a==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print((a == 0)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65, 768]) torch.Size([32, 64])\n",
      "torch.Size([0, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones((32, 65, 768))\n",
    "b = torch.ones((32, 64))==torch.ones((32, 64))\n",
    "print(a.shape,b.shape)\n",
    "c = a[:,1:][b]\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0011)\n",
      "tensor(-0.0011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.rand((1, 64)).float()\n",
    "ground_truth1 = torch.tensor([[0]]).float()\n",
    "ground_truth2 = torch.tensor([[0]]).float()\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(64, 8, bias=False)\n",
    "        self.layer2 = nn.Linear(8, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        return F.sigmoid(out1), F.sigmoid(out2)\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), 0.01)\n",
    "output1, output2 = model(input)\n",
    "\n",
    "loss1 = F.mse_loss(output1, ground_truth1)\n",
    "loss2 = F.mse_loss(output2, ground_truth2)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss1.backward(retain_graph=True)\n",
    "loss2.backward(retain_graph=True)\n",
    "print(model.layer1.weight.grad[0, 0])\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss = (loss1 + loss2)\n",
    "loss.backward()\n",
    "print(model.layer1.weight.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-436f27df9a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0moptimizer_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mout_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             raise RuntimeError(\"Only Tensors created explicitly by the user \"\n\u001b[0m\u001b[1;32m     48\u001b[0m                                \"(graph leaves) support the deepcopy protocol at the moment\")\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "input = torch.rand((1, 64)).float()\n",
    "ground_truth1 = torch.tensor([[0]]).float()\n",
    "ground_truth2 = torch.tensor([[0]]).float()\n",
    "\n",
    "\n",
    "class A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(A, self).__init__()\n",
    "        self.layer1 = nn.Linear(64, 8, bias=False)\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        return out1\n",
    "class B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()\n",
    "        self.layer2 = nn.Linear(8, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        out2 = self.layer2(x)\n",
    "        return F.sigmoid(out2)\n",
    "\n",
    "A = A()\n",
    "B = B()\n",
    "model.train()\n",
    "\n",
    "optimizer_a = optim.SGD(A.parameters(), 0.01)\n",
    "optimizer_b = optim.SGD(B.parameters(), 0.01)\n",
    "out_a = A(input)\n",
    "out_b = B(copy.deepcopy(out_a))\n",
    "\n",
    "loss1 = F.mse_loss(out_b, ground_truth1)\n",
    "# loss2 = F.mse_loss(output2, ground_truth2)\n",
    "\n",
    "optimizer_a.zero_grad()\n",
    "optimizer_b.zero_grad()\n",
    "loss1.backward(retain_graph=True)#retain_graph=True\n",
    "optimizer_a.step()\n",
    "optimizer_b.step()\n",
    "# loss1.backward(retain_graph=True)#retain_graph=True\n",
    "loss1 = F.mse_loss(out_b, ground_truth1)\n",
    "loss1.backward()\n",
    "# loss1.backward(retain_graph=True)\n",
    "# loss1.backward(retain_graph=True)\n",
    "# loss1.backward(retain_graph=True)\n",
    "\n",
    "# optimizer_b.step()\n",
    "# loss2.backward()\n",
    "# print(model.layer1.weight.grad[0, 0])\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# loss = (loss1 + loss2)\n",
    "# loss.backward()\n",
    "# print(model.layer1.weight.grad[0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
